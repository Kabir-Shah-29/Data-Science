{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic Clustering:-Intrinsic Measures: These measures do not require ground truth labels (applicable to all unsupervised \n",
    "# learning result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7545b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: 0.2871407974806454\n"
     ]
    }
   ],
   "source": [
    "# Silhouette Coefficient\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def calculate_silhouette_coefficient(data, num_clusters):\n",
    "    # Perform clustering using K-means\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    labels = kmeans.fit_predict(data)\n",
    "    \n",
    "    # Calculate the Silhouette Coefficient\n",
    "    silhouette_coefficient = silhouette_score(data, labels)\n",
    "    \n",
    "    return silhouette_coefficient\n",
    "\n",
    "# Example usage\n",
    "data = [[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]]\n",
    "num_clusters = 2\n",
    "\n",
    "silhouette_coefficient = calculate_silhouette_coefficient(data, num_clusters)\n",
    "print(\"Silhouette Coefficient:\", silhouette_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd19601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "labels = kmeans.fit_predict(data)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4adb4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Davies-Bouldin Index: It measures the average similarity between clusters, considering both the compactness and separation. \n",
    "#     Lower values indicate better-defined clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c345a565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3412044467949961"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.cluster import KMeans\n",
    "data = [\n",
    "    [5.1, 3.5, 1.4, 0.2],\n",
    "    [4.9, 3. , 1.4, 0.2],\n",
    "    [4.7, 3.2, 1.3, 0.2],\n",
    "    [4.6, 3.1, 1.5, 0.2],\n",
    "    [5. , 3.6, 1.4, 0.2],\n",
    "    [5.4, 3.9, 1.7, 0.4],\n",
    "]\n",
    "num_clusters=3\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "labels = kmeans.fit_predict(data)\n",
    "labels\n",
    "\n",
    "DB = davies_bouldin_score(data, labels)\n",
    "DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09651dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2defec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calinski-Harabasz Index measures the between-cluster dispersion against within-cluster dispersion. A higher score signifies \n",
    "# better-defined clusters.\n",
    "\n",
    "# The Calinski-Harabasz Index, or Variance Ratio Criterion, measures the sum of between-cluster dispersion against the sum of\n",
    "# within-cluster dispersion, where dispersion is the sum of distance squared.\n",
    "\n",
    "# A higher ratio signifies the cluster is far away from its other clusters and that the cluster is more well-defined. The \n",
    "# formula is found in this articleâ€™s Appendix (Fig 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08fba583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.060344827586167"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score\n",
    "data = [\n",
    "    [5.1, 3.5, 1.4, 0.2],\n",
    "    [4.9, 3. , 1.4, 0.2],\n",
    "    [4.7, 3.2, 1.3, 0.2],\n",
    "    [4.6, 3.1, 1.5, 0.2],\n",
    "    [5. , 3.6, 1.4, 0.2],\n",
    "    [5.4, 3.9, 1.7, 0.4],\n",
    "]\n",
    "num_clusters=3\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "clusters = kmeans.fit_predict(data)\n",
    "# clusters = [1, 1, 2, 2, 3, 3]\n",
    "\n",
    "s = calinski_harabasz_score(data, clusters)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e127a927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb7aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic Evaluation:\n",
    "# Intrinsic evaluation assesses the quality of a clustering algorithm based on the characteristics of the clusters themselves. It \n",
    "# focuses on internal measures and does not rely on external information or ground truth labels. Some commonly used intrinsic \n",
    "\n",
    "# evaluation metrics are:\n",
    "\n",
    "# Silhouette Coefficient: Measures the compactness and separation of clusters.\n",
    "# Calinski-Harabasz Index: Evaluates the ratio of between-cluster dispersion to within-cluster dispersion.\n",
    "# Davies-Bouldin Index: Quantifies the average similarity between clusters.\n",
    "# These metrics provide insights into the quality and coherence of the clusters generated by the algorithm.\n",
    "\n",
    "# Extrinsic Evaluation:\n",
    "# Extrinsic evaluation involves assessing the performance of a clustering algorithm by comparing the clustering results with \n",
    "# externally available information or ground truth labels. In this approach, the quality of the clusters is evaluated based on\n",
    "# how well they align with the known labels or external information. Some commonly used extrinsic evaluation metrics are:\n",
    "\n",
    "# Adjusted Rand Index (ARI): Measures the similarity between two clusterings, taking into account all pairs of samples and their \n",
    "# agreements.\n",
    "# Normalized Mutual Information (NMI): Quantifies the mutual information between two clusterings, considering the class labels.\n",
    "# These metrics require having access to ground truth labels or external information to assess the algorithm's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2610a0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# True labels or ground truth\n",
    "true_labels = [0, 0, 1, 1, 2, 2]\n",
    "\n",
    "# Predicted labels from a clustering algorithm\n",
    "num_clusters=3\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "predicted_labels= kmeans.fit_predict(data)\n",
    "# predicted_labels = [0, 0, 1, 1, 3, 3]\n",
    "\n",
    "# Calculate the Adjusted Rand Index\n",
    "ari = adjusted_rand_score(true_labels, predicted_labels)\n",
    "print(ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b889f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "# True labels or ground truth\n",
    "true_labels = [0, 0, 1, 1, 2, 2]\n",
    "\n",
    "# Predicted labels from a clustering algorithm\n",
    "num_clusters=3\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "predicted_labels = kmeans.fit_predict(data)\n",
    "# predicted_labels = [0, 0, 1, 1, 3, 3]\n",
    "\n",
    "# Calculate the Normalized Mutual Information\n",
    "nmi = normalized_mutual_info_score(true_labels, predicted_labels)\n",
    "print(nmi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
